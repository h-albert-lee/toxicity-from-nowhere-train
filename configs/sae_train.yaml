sae:
  type: topk
  latent_ratio: 4.0
  topk: 64
  weight_decay: 0.0
  lr: 3e-4
  epochs: 12
  batch_size: 2048
  val_fraction: 0.05

normalization:
  scheme: global_mean_std

layers: [0, 2, 4]

io:
  in_dir: artifacts/activations/llavaguard
  out_dir: artifacts/sae/llavaguard
  scaler_filename: scaler_layer{l}.json
  sae_filename: sae_layer{l}.pt
